"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í´ë¼ì´ì–¸íŠ¸
"""
import os
import httpx
from typing import List, Dict, Optional
from datetime import datetime, timedelta


class NaverNewsAPI:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API í´ë˜ìŠ¤"""

    def __init__(self):
        self.client_id = os.getenv("NAVER_CLIENT_ID")
        self.client_secret = os.getenv("NAVER_CLIENT_SECRET")
        self.base_url = "https://openapi.naver.com/v1/search/news.json"

        if not self.client_id or not self.client_secret:
            raise ValueError("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    async def search_news(
        self,
        query: str,
        display: int = 10,
        start: int = 1,
        sort: str = "date"
    ) -> Optional[List[Dict]]:
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ì–´
            display: ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ê±´ìˆ˜ (ìµœëŒ€ 100)
            start: ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (ìµœëŒ€ 1000)
            sort: ì •ë ¬ ì˜µì…˜ (date: ë‚ ì§œìˆœ, sim: ì •í™•ë„ìˆœ)

        Returns:
            ë‰´ìŠ¤ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            headers = {
                "X-Naver-Client-Id": self.client_id,
                "X-Naver-Client-Secret": self.client_secret,
            }

            params = {
                "query": query,
                "display": display,
                "start": start,
                "sort": sort,
            }

            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    self.base_url,
                    headers=headers,
                    params=params
                )

                if response.status_code == 200:
                    data = response.json()
                    return data.get("items", [])
                else:
                    print(f"âš ï¸ ë„¤ì´ë²„ API ì˜¤ë¥˜: {response.status_code}")
                    print(f"   ì‘ë‹µ: {response.text}")
                    return None

        except Exception as e:
            print(f"âŒ ë„¤ì´ë²„ API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return None

    def clean_html_tags(self, text: str) -> str:
        """
        HTML íƒœê·¸ ì œê±°

        Args:
            text: HTML íƒœê·¸ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸

        Returns:
            íƒœê·¸ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        import re
        # <b>, </b> ë“± íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text)
        # HTML ì—”í‹°í‹° ë³€í™˜
        clean_text = clean_text.replace('&quot;', '"')
        clean_text = clean_text.replace('&amp;', '&')
        clean_text = clean_text.replace('&lt;', '<')
        clean_text = clean_text.replace('&gt;', '>')
        return clean_text

    def parse_news_item(self, item: Dict) -> Dict:
        """
        ë„¤ì´ë²„ API ì‘ë‹µ íŒŒì‹±

        Args:
            item: ë„¤ì´ë²„ API ë‰´ìŠ¤ ì•„ì´í…œ

        Returns:
            íŒŒì‹±ëœ ë‰´ìŠ¤ ë°ì´í„°
        """
        # HTML íƒœê·¸ ì œê±°
        title = self.clean_html_tags(item.get("title", ""))
        description = self.clean_html_tags(item.get("description", ""))

        # ë‚ ì§œ íŒŒì‹± (YYYYMMDD í˜•ì‹)
        pub_date_str = item.get("pubDate", "")
        try:
            # "Tue, 14 Jan 2025 10:30:00 +0900" í˜•ì‹ íŒŒì‹±
            pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %z")
        except:
            pub_date = datetime.now()

        return {
            "title": title,
            "content": description,
            "url": item.get("originallink") or item.get("link"),
            "published_at": pub_date.isoformat(),
            "source": "Naver ë‰´ìŠ¤ ê²€ìƒ‰",
        }

    async def search_stock_news(
        self,
        stock_name: str,
        max_results: int = 5
    ) -> List[Dict]:
        """
        íŠ¹ì • ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰

        Args:
            stock_name: ì¢…ëª©ëª… (ì˜ˆ: "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤")
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            íŒŒì‹±ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        # ê²€ìƒ‰ì–´ ìµœì í™”
        query = f"{stock_name} ì£¼ê°€ OR {stock_name} ì‹¤ì "

        items = await self.search_news(query=query, display=max_results, sort="date")

        if not items:
            return []

        # íŒŒì‹±
        parsed_news = []
        for item in items:
            parsed = self.parse_news_item(item)
            parsed_news.append(parsed)

        return parsed_news

    async def search_multiple_stocks(
        self,
        stock_names: List[str],
        results_per_stock: int = 5
    ) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì¢…ëª© ë‰´ìŠ¤ ë™ì‹œ ê²€ìƒ‰

        Args:
            stock_names: ì¢…ëª©ëª… ë¦¬ìŠ¤íŠ¸
            results_per_stock: ì¢…ëª©ë‹¹ ê²°ê³¼ ìˆ˜

        Returns:
            ëª¨ë“  ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°ë¨)
        """
        all_news = []
        seen_urls = set()

        for stock_name in stock_names:
            print(f"ğŸ” {stock_name} ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")

            news_items = await self.search_stock_news(stock_name, results_per_stock)

            # ì¤‘ë³µ ì œê±°
            for news in news_items:
                url = news["url"]
                if url not in seen_urls:
                    seen_urls.add(url)
                    all_news.append(news)

        print(f"âœ… ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±° í›„)")
        return all_news


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    import asyncio
    from dotenv import load_dotenv

    load_dotenv()

    async def test():
        api = NaverNewsAPI()

        # ë‹¨ì¼ ì¢…ëª© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n=== ì‚¼ì„±ì „ì ë‰´ìŠ¤ ê²€ìƒ‰ ===")
        news = await api.search_stock_news("ì‚¼ì„±ì „ì", max_results=3)

        for item in news:
            print(f"\nì œëª©: {item['title']}")
            print(f"ë‚´ìš©: {item['content'][:100]}...")
            print(f"URL: {item['url']}")
            print(f"ë°œí–‰ì¼: {item['published_at']}")

        # ë‹¤ì¤‘ ì¢…ëª© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n\n=== ë‹¤ì¤‘ ì¢…ëª© ë‰´ìŠ¤ ê²€ìƒ‰ ===")
        stocks = ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "NAVER"]
        all_news = await api.search_multiple_stocks(stocks, results_per_stock=2)

        print(f"\nì´ {len(all_news)}ê°œ ë‰´ìŠ¤")

    asyncio.run(test())
